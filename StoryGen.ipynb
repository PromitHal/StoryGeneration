{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c82caea-64a0-4dea-b8e8-c75c095710c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/phaldar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import re\n",
    "import nltk\n",
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6644c2f-0833-4c47-8fcd-3368fe38a503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17025"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text:str)->list[str]:\n",
    "    text=text.replace('\\n','')\n",
    "    text=text.split('.')\n",
    "    text=[item+'.' for item in text]\n",
    "    return text\n",
    "\n",
    "def read_data(path:str):\n",
    "    text=''\n",
    "    with open(path,'r') as f:\n",
    "        text=f.read()\n",
    "        f.close()\n",
    "    text=preprocess(text)\n",
    "    return text \n",
    "text=read_data('1-18 books combined.txt')\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5387e1af-dc21-4ecc-b499-216e7b9c3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The cat jumped over the fence.\",\n",
    "    \"She went to the market to buy apples.\",\n",
    "    \"He loves reading books on rainy days.\",\n",
    "    \"They are playing football in the park.\",\n",
    "    \"Can you help me with my homework?\",\n",
    "    \"The dog barked at the mailman.\",\n",
    "    \"We are planning a trip to the mountains.\",\n",
    "    \"She smiled and walked away.\",\n",
    "    \"He always wakes up early in the morning.\",\n",
    "    \"The boy is afraid of the dark.\",\n",
    "    \"It was a bright and sunny day.\",\n",
    "    \"Why are you late today?\",\n",
    "    \"The phone rang loudly in the middle of the night.\",\n",
    "    \"She baked a delicious chocolate cake.\",\n",
    "    \"He forgot his umbrella at home.\",\n",
    "    \"The baby laughed when she saw the toy.\",\n",
    "    \"They are waiting for the bus at the station.\",\n",
    "    \"She looked at the sky and sighed.\",\n",
    "    \"Can you tell me a story?\",\n",
    "    \"The children were excited to see the circus.\",\n",
    "    \"He wrote a letter to his friend.\",\n",
    "    \"She painted a beautiful landscape.\",\n",
    "    \"They are learning how to swim.\",\n",
    "    \"He was running late for his meeting.\",\n",
    "    \"She whispered a secret into his ear.\",\n",
    "    \"The teacher asked a difficult question.\",\n",
    "    \"The sun was setting behind the hills.\",\n",
    "    \"They danced all night at the party.\",\n",
    "    \"She opened the door and saw a surprise.\",\n",
    "    \"What do you want to eat for dinner?\",\n",
    "    \"The stars shone brightly in the sky.\",\n",
    "    \"He found an old coin in the garden.\",\n",
    "    \"They built a sandcastle on the beach.\",\n",
    "    \"She sang a song softly.\",\n",
    "    \"The bird flew away from the nest.\",\n",
    "    \"He is fixing his bike in the garage.\",\n",
    "    \"Do you know the way to the library?\",\n",
    "    \"The car stopped suddenly on the road.\",\n",
    "    \"She lost her keys somewhere in the house.\",\n",
    "    \"They are watching a movie together.\",\n",
    "    \"The coffee is too hot to drink.\",\n",
    "    \"He gave her a bouquet of flowers.\",\n",
    "    \"She wants to become a doctor.\",\n",
    "    \"The dog is chasing a ball.\",\n",
    "    \"He closed the book and fell asleep.\",\n",
    "    \"Are you coming to the party?\",\n",
    "    \"She waited patiently for the train.\",\n",
    "    \"The snow covered everything in white.\",\n",
    "    \"He bought a new pair of shoes.\",\n",
    "    \"She hugged her friend tightly.\",\n",
    "    \"The wind is blowing through the trees.\",\n",
    "    \"They are painting the walls of their house.\",\n",
    "    \"He is practicing the guitar every evening.\",\n",
    "    \"She walked barefoot on the grass.\",\n",
    "    \"The clock struck twelve.\",\n",
    "    \"They are setting up the tent for camping.\",\n",
    "    \"The dog wagged its tail happily.\",\n",
    "    \"She gave him a gift on his birthday.\",\n",
    "    \"He told a funny joke to his friends.\",\n",
    "    \"They are playing chess in the living room.\",\n",
    "    \"The moon is full tonight.\",\n",
    "    \"He is writing a story about adventures.\",\n",
    "    \"She is learning how to dance.\",\n",
    "    \"They went for a walk by the river.\",\n",
    "    \"The rain is falling gently.\",\n",
    "    \"He made a sandwich for lunch.\",\n",
    "    \"She tied her hair in a ponytail.\",\n",
    "    \"They are solving a puzzle together.\",\n",
    "    \"He cleaned the kitchen after dinner.\",\n",
    "    \"She turned off the lights and went to bed.\",\n",
    "    \"The flowers are blooming in the garden.\",\n",
    "    \"He threw a stone into the water.\",\n",
    "    \"She waved goodbye to her friends.\",\n",
    "    \"They are playing hide-and-seek.\",\n",
    "    \"The bird is building a nest.\",\n",
    "    \"He is watching the stars through a telescope.\",\n",
    "    \"She is writing a poem about love.\",\n",
    "    \"They built a fire in the fireplace.\",\n",
    "    \"The kitten is playing with a ball of yarn.\",\n",
    "    \"He saw a rainbow in the sky.\",\n",
    "    \"She opened the window to let in fresh air.\",\n",
    "    \"They are making plans for the weekend.\",\n",
    "    \"He helped her carry the groceries.\",\n",
    "    \"She listened to music on her headphones.\",\n",
    "    \"The leaves are falling from the trees.\",\n",
    "    \"He is waiting for the bus to arrive.\",\n",
    "    \"She wore a red dress to the party.\",\n",
    "    \"They are learning a new language.\",\n",
    "    \"He found a treasure map.\",\n",
    "    \"She is knitting a scarf for winter.\",\n",
    "    \"The waves are crashing on the shore.\",\n",
    "    \"He baked bread in the oven.\",\n",
    "    \"She read a bedtime story to the children.\",\n",
    "    \"They are taking photos of the sunset.\",\n",
    "    \"He fixed the broken chair.\",\n",
    "    \"She is watering the plants.\",\n",
    "    \"The baby is sleeping peacefully.\",\n",
    "    \"He drew a picture of a house.\",\n",
    "    \"She is feeding the birds in the park.\",\n",
    "    \"They are having a picnic under the tree.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "448a2e8a-aafa-494a-ab9c-2828f6fb2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Sentence: he loves reading books on rainy days .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def custom_tokenize(sentence):\n",
    "    tokens = re.split(r'(\\W)', sentence.lower())  # Tokenize words and punctuation\n",
    "    tokens = [token for token in tokens if token.strip()]  \n",
    "    return tokens\n",
    "\n",
    "def tokenize_sentences(sentences, max_len=100):\n",
    "    tokenized = [custom_tokenize(sentence)[:max_len] for sentence in sentences]\n",
    "    return tokenized\n",
    "\n",
    "def build_vocab(tokenized_sentences):\n",
    "    word_counts = Counter([word for sentence in tokenized_sentences for word in sentence])\n",
    "    vocab = {word: idx for idx, (word, _) in enumerate(word_counts.items(), start=1)}\n",
    "    vocab['<PAD>'] = 0  # Add PAD token with index 0\n",
    "    idx2word = {idx: word for word, idx in vocab.items()}  \n",
    "    return vocab, idx2word\n",
    "\n",
    "def sentences_to_sequences(tokenized_sentences, vocab):\n",
    "    return [[vocab[word] for word in sentence] for sentence in tokenized_sentences]\n",
    "\n",
    "def pad_sequences(sequences, max_len, pad_type='pre'):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if pad_type == 'post':\n",
    "            padded = seq + [0] * (max_len - len(seq))\n",
    "        else:  # Pre-padding\n",
    "            padded = [0] * (max_len - len(seq)) + seq\n",
    "        padded_sequences.append(padded[:max_len])  # Ensure max_len\n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "tokenized_sentences = tokenize_sentences(sentences, max_len=10)\n",
    "vocab, idx2word = build_vocab(tokenized_sentences)\n",
    "\n",
    "sequences = sentences_to_sequences(tokenized_sentences, vocab)\n",
    "\n",
    "max_len = 10  # Maximum sequence length\n",
    "pad_type = 'pre'  # Padding type (pre or post)\n",
    "padded_sequences = pad_sequences(sequences, max_len, pad_type)\n",
    "\n",
    "# Example: Convert predicted indices back to words\n",
    "def decode_sequence(sequence, idx2word):\n",
    "    return [idx2word[idx] for idx in sequence if idx != 0]  # Ignore PAD tokens\n",
    "\n",
    "# Test decoding a sequence\n",
    "decoded_sentence = decode_sequence(padded_sequences[2], idx2word)\n",
    "print(\"Decoded Sentence:\", ' '.join(decoded_sentence))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c587c13-6f7d-44b6-9ac3-5c08556f796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_len=20\n",
    "pad_type='pre'\n",
    "\n",
    "padded_sequences=pad_sequences(sequences,max_len,pad_type)\n",
    "input_tensor=torch.tensor(padded_sequences,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d1f44650-e0bc-4e5c-911c-0147cdae0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryLSTM(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,hiddem_size,num_layers):\n",
    "        super(StoryLSTM,self).__init__()\n",
    "        #Input: batch_size*seq_len\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        #Input: batch_size*seq_len*embed_size\n",
    "        self.lstm=nn.LSTM(embed_size,hidden_size,num_layers,batch_first=True)\n",
    "        #Input: batch_size*hidden_size\n",
    "        self.fc=nn.Linear(hidden_size,vocab_size)\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        #Input: batch_size*seq_len\n",
    "        x=self.embedding(x)\n",
    "        #Input: batch_size*seq_len*embed_size\n",
    "        out,(hn,cn)=self.lstm(x,h)\n",
    "        #Input: batch_size*max_seq_len*hidden_size\n",
    "        out=self.fc(out)\n",
    "        return out,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "72657856-91ef-4437-8a8e-4c7f18b9f23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoryLSTM(\n",
       "  (embedding): Embedding(324, 128)\n",
       "  (lstm): LSTM(128, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=324, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(vocab)\n",
    "embed_size=128\n",
    "hidden_size=256\n",
    "num_layers=1\n",
    "model=StoryLSTM(vocab_size,embed_size,hidden_size,num_layers)\n",
    "model=model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ff184e51-45b9-4070-9157-e5e5e84c04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor=torch.tensor(padded_sequences,dtype=torch.long)\n",
    "target_tensor=input_tensor[:,1:]\n",
    "input_tensor=input_tensor[:,:-1]\n",
    "batch_size=5\n",
    "dataset=TensorDataset(input_tensor,target_tensor)\n",
    "data_loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "caebbeab-d81c-4286-8586-0b7239a5c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"mps\" if torch.backends.mps.is_available() else\"cpu\")\n",
    "optimizer=torch.optim.Adam(params=model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8710be7e-08ac-463b-b2c8-faf031479731",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=5\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs,label in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        total_loss=0\n",
    "    \n",
    "        hidden=(\n",
    "            torch.zeros(1,batch_size,256).to(device),\n",
    "            torch.zeros(1,batch_size,256).to(device)\n",
    "        )\n",
    "        inputs=inputs.to(device) \n",
    "        label=label.to(device)\n",
    "        outputs,_=model(inputs,hidden)\n",
    "        outputs=outputs.view(-1,outputs.size(-1))\n",
    "        label=label.view(-1)\n",
    "        loss=ce(outputs,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c87d9a41-5575-4c16-8441-9c5d8b898951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ef1aa95a-f84f-47cb-954d-c066dc30585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'are', 'are', 'are']\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "seed_text='They'\n",
    "warnings.filterwarnings('ignore')\n",
    "preds=[]\n",
    "model.eval()\n",
    "tokens = [vocab.get(word, vocab['<PAD>']) for word in seed_text.lower().split()]\n",
    "input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, seq_len)\n",
    "batch_size=input_seq.size(0) \n",
    "hidden=(\n",
    "    torch.zeros(1,batch_size,hidden_size).to(device),\n",
    "    torch.zeros(1,batch_size,hidden_size).to(device)\n",
    ")\n",
    "genereated_text=seed_text\n",
    "\n",
    "for _ in range(4):\n",
    "    with torch.no_grad():\n",
    "        output,hidden=model(input_seq,hidden)\n",
    "    probs=torch.softmax(output[:,-1:,:].squeeze(),dim=0)\n",
    "    preds.append(idx2word[np.argmax(probs.detach().cpu().numpy())])\n",
    "    req_idx=torch.argmax(probs.squeeze().detach().cpu(),dim=0)\n",
    "    input_seq=torch.tensor(input_seq.clone().detach()).to(device)\n",
    "    \n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f1f6e2a4-626f-421e-94f5-e5dae2d507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text, vocab, idx2word, device, max_len=20):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the seed text\n",
    "    tokens = [vocab.get(word, vocab['<PAD>']) for word in seed_text.lower().split()]\n",
    "    input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, seq_len)\n",
    "\n",
    "    # Dynamically extract the batch size from input_seq\n",
    "    batch_size = input_seq.size(0)  # This will be 1 for inference\n",
    "\n",
    "    # Initialize the hidden state to match the batch size\n",
    "    hidden = (\n",
    "        torch.zeros(model.lstm.num_layers, batch_size, model.lstm.hidden_size).to(device),\n",
    "        torch.zeros(model.lstm.num_layers, batch_size, model.lstm.hidden_size).to(device)\n",
    "    )\n",
    "\n",
    "    generated_text = seed_text\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            # Forward pass through the model\n",
    "            output, hidden = model(input_seq, hidden)  # Input shape: (1, seq_len)\n",
    "\n",
    "        # Get the prediction from the last time step\n",
    "        output = output[:, -1, :]  # Shape: (1, vocab_size)\n",
    "        probs = torch.softmax(output, dim=-1).cpu().numpy()  # Convert to probabilities\n",
    "\n",
    "        # Sample the next word index from the probabilities\n",
    "        next_word_idx = torch.multinomial(torch.tensor(probs), 1).item()\n",
    "\n",
    "        # Stop if PAD token is predicted\n",
    "        if next_word_idx == vocab['<PAD>']:\n",
    "            break\n",
    "\n",
    "        # Convert the index to a word and append it to the generated text\n",
    "        next_word = idx2word[next_word_idx]\n",
    "        generated_text += ' ' + next_word\n",
    "\n",
    "        # Update the input sequence with the new word\n",
    "        input_seq = torch.tensor([[next_word_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5fb823f7-1ef3-48c3-a59a-580fd1c68e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text=\"He baked bread\"\n",
    "tokens = [vocab.get(word, vocab['<PAD>']) for word in seed_text.lower().split()]\n",
    "input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "30bcd52f-daf1-4ab5-832e-bfb899fb8c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 13,  70, 302]], device='mps:0')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "422a5bf9-0a4f-4dbc-8373-9af9b737e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = (\n",
    "    torch.zeros(model.lstm.num_layers, 1, model.lstm.hidden_size).to(device),\n",
    "    torch.zeros(model.lstm.num_layers, 1, model.lstm.hidden_size).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "88db97d4-98ca-4986-b0aa-710d7ed37e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "output,_=model(input_seq,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e3ef9a24-e876-4d2b-a342-784230485d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 324])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3f2a988a-2e73-490a-9b46-10a5893a7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(output, dim=-1).detach().cpu().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b2357a78-dd49-45cb-a6b4-a4f1617a9bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "prob_dist must be 1 or 2 dim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m next_word_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(torch\u001b[38;5;241m.\u001b[39mtensor(probs), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: prob_dist must be 1 or 2 dim"
     ]
    }
   ],
   "source": [
    "next_word_idx = torch.multinomial(torch.tensor(probs), 1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a38894ff-5f37-43b0-8902-4efdbe5f6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9232937a-c526-4ee8-b5eb-5a06baed2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.argmax(torch.softmax(output[-1][-1],dim=0).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "54312879-67b3-4ee2-9618-b0a2126b2844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "31607d36-6e09-4ccf-813c-b996917fdca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "inputs=torch.randint(low=0,high=100,size=(1,5)).to(device)\n",
    "hidden = (\n",
    "    torch.zeros(model.lstm.num_layers, 1, model.lstm.hidden_size).to(device),\n",
    "    torch.zeros(model.lstm.num_layers, 1, model.lstm.hidden_size).to(device)\n",
    ")\n",
    "with torch.no_grad():\n",
    "    op=model(inputs,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a6e34dae-baa1-4568-ae7e-b82cc945b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,hidden=op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "121f0c01-d840-4f71-844c-7a9f75239cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2f9344ad-e2b5-49d9-8cc4-2049be95714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: He letter keys fixed after\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seed text to start generating the sequence\n",
    "seed_text = 'He'\n",
    "preds = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Convert seed text to tokens and input sequence tensor\n",
    "tokens = [vocab.get(word, vocab['<PAD>']) for word in seed_text.lower().split()]\n",
    "input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, seq_len)\n",
    "\n",
    "# Initialize the hidden state\n",
    "batch_size = input_seq.size(0)  # Should be 1 for inference\n",
    "hidden = (\n",
    "    torch.zeros(1, batch_size, hidden_size).to(device),\n",
    "    torch.zeros(1, batch_size, hidden_size).to(device)\n",
    ")\n",
    "\n",
    "# Initialize the generated text\n",
    "generated_text = seed_text\n",
    "\n",
    "# Generate 4 words sequentially\n",
    "for _ in range(4):\n",
    "    with torch.no_grad():\n",
    "        output, hidden = model(input_seq, hidden)  # Forward pass through the model\n",
    "\n",
    "    # Get the probabilities of the last time step\n",
    "    probs = torch.softmax(output[:, -1, :], dim=-1)  # Shape: (1, vocab_size)\n",
    "\n",
    "    # Get the predicted word index using multinomial sampling for randomness\n",
    "    next_word_idx = torch.multinomial(probs, 1).item()\n",
    "\n",
    "    # Convert index to word and add to the generated text\n",
    "    next_word = idx2word[next_word_idx]\n",
    "    preds.append(next_word)\n",
    "    generated_text += ' ' + next_word\n",
    "\n",
    "    # Update input sequence with the predicted word index\n",
    "    input_seq = torch.tensor([[next_word_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2693ad26-471f-4c00-bf3a-0ca61006dfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: He falling weekend night market\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def generate_sequence(model, seed_text, vocab, idx2word, device, hidden_size, num_words=4):\n",
    "    \"\"\"\n",
    "    Generate a sequence of text based on a seed input.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained LSTM model for text generation.\n",
    "    - seed_text: Initial text to start generating from.\n",
    "    - vocab: Dictionary mapping words to their token indices.\n",
    "    - idx2word: Dictionary mapping token indices back to words.\n",
    "    - device: Device (CPU or GPU) for tensor computations.\n",
    "    - hidden_size: Size of hidden state in the LSTM.\n",
    "    - num_words: Number of words to generate.\n",
    "\n",
    "    Returns:\n",
    "    - generated_text: Complete text generated from the model.\n",
    "    \"\"\"\n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Convert seed text to tokens and input sequence tensor\n",
    "    tokens = [vocab.get(word, vocab['<PAD>']) for word in seed_text.lower().split()]\n",
    "    input_seq = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, seq_len)\n",
    "\n",
    "    # Initialize hidden state\n",
    "    batch_size = input_seq.size(0)\n",
    "    hidden = (\n",
    "        torch.zeros(1, batch_size, hidden_size).to(device),\n",
    "        torch.zeros(1, batch_size, hidden_size).to(device)\n",
    "    )\n",
    "\n",
    "    generated_text = seed_text  # Start with seed text\n",
    "    preds = []\n",
    "\n",
    "    # Generate the specified number of words\n",
    "    for _ in range(num_words):\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "\n",
    "        # Get probabilities from the last time step\n",
    "        probs = torch.softmax(output[:, -1, :], dim=-1)\n",
    "\n",
    "        # Sample the next word index\n",
    "        next_word_idx = torch.multinomial(probs, 1).item()\n",
    "\n",
    "        # Stop if PAD token is generated\n",
    "        if next_word_idx == vocab['<PAD>']:\n",
    "            break\n",
    "\n",
    "        # Get the word and add it to the text\n",
    "        next_word = idx2word[next_word_idx]\n",
    "        preds.append(next_word)\n",
    "        generated_text += ' ' + next_word\n",
    "\n",
    "        # Update input sequence with the predicted word\n",
    "        input_seq = torch.tensor([[next_word_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "generated_text = generate_sequence(\n",
    "    model=model,\n",
    "    seed_text='He',\n",
    "    vocab=vocab,\n",
    "    idx2word=idx2word,\n",
    "    device=device,\n",
    "    hidden_size=256,\n",
    "    num_words=4\n",
    ")\n",
    "\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514f4a8-d53d-4460-8db4-c71c95a9cb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a3e5e-0c09-4a5b-8853-5dc6294acb46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
